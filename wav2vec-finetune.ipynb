{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f4d09d93e14a4602b9314a70fe1ce2df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0cab286e6f5f47468aa87a25179af6f3","IPY_MODEL_416a1437a3f34fcaa4160e1b2cccfe0e","IPY_MODEL_dae1897161ca498bbfc8938b47ef0107"],"layout":"IPY_MODEL_9ec7f18cc48e4ac7a56b306822698dd9"}},"0cab286e6f5f47468aa87a25179af6f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e677a5211749d4a298cd23a10b047b","placeholder":"​","style":"IPY_MODEL_aa4668eb7440479392d9792814fc6bee","value":"Generating train split: "}},"416a1437a3f34fcaa4160e1b2cccfe0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa3623f0d9604f42a8a618c14a9ca6ec","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_51132c64186140a58e098713af1f284a","value":1}},"dae1897161ca498bbfc8938b47ef0107":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8256d41489a54007947fb24b3e0028ee","placeholder":"​","style":"IPY_MODEL_0cb75493f1264676a07813adb888f7a3","value":" 2187/0 [00:37&lt;00:00, 63.24 examples/s]"}},"9ec7f18cc48e4ac7a56b306822698dd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e677a5211749d4a298cd23a10b047b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa4668eb7440479392d9792814fc6bee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa3623f0d9604f42a8a618c14a9ca6ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"51132c64186140a58e098713af1f284a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8256d41489a54007947fb24b3e0028ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cb75493f1264676a07813adb888f7a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62735839f15c4cd6ad738c6c3d4eea2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a802392ffe15498fbb8835774d695590","IPY_MODEL_4ec30f0592474944beb100b4f0f51aee","IPY_MODEL_57092a5f17194077b80635f13a35a01e"],"layout":"IPY_MODEL_3166e2c21ad4428c926b17e0a6d14581"}},"a802392ffe15498fbb8835774d695590":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15e84d8397ca409793649d925b2402ac","placeholder":"​","style":"IPY_MODEL_eeeb28461acd419aa27769db4f6210fc","value":"config.json: 100%"}},"4ec30f0592474944beb100b4f0f51aee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b4d11899dde4549b6e4e3e24c411d49","max":2039,"min":0,"orientation":"horizontal","style":"IPY_MODEL_034231d6f2674e68afbd6a072b63f498","value":2039}},"57092a5f17194077b80635f13a35a01e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cfe60e179ff4cf0bfeb4b9fb25e1e14","placeholder":"​","style":"IPY_MODEL_3c51d1e214c6466e8f747c2423768fb0","value":" 2.04k/2.04k [00:00&lt;00:00, 176kB/s]"}},"3166e2c21ad4428c926b17e0a6d14581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15e84d8397ca409793649d925b2402ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeeb28461acd419aa27769db4f6210fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b4d11899dde4549b6e4e3e24c411d49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"034231d6f2674e68afbd6a072b63f498":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cfe60e179ff4cf0bfeb4b9fb25e1e14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c51d1e214c6466e8f747c2423768fb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be1e44f5202d4ca3b5e7ee6cf9b19761":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab0920ee35b147f9bf26a78492e3ae3f","IPY_MODEL_1d3b30615fe4438282b37fd026de579c","IPY_MODEL_50ce68feadcb4da58ac18e686d30cbd4"],"layout":"IPY_MODEL_de1b207d77904426accc2cf89de969ec"}},"ab0920ee35b147f9bf26a78492e3ae3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d30dc960bab648d6876547c515a80857","placeholder":"​","style":"IPY_MODEL_16992efb50344254aeb8bd83075d75fc","value":"model.safetensors: 100%"}},"1d3b30615fe4438282b37fd026de579c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7cbb0bb36c648a2b732ee81f25f3070","max":380246024,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9549b550b85d404b996d651524da93da","value":380246024}},"50ce68feadcb4da58ac18e686d30cbd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_387e4001627c41fead717e26c0db101b","placeholder":"​","style":"IPY_MODEL_02d0daa75852468cb273f23982f70b36","value":" 380M/380M [00:07&lt;00:00, 66.3MB/s]"}},"de1b207d77904426accc2cf89de969ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d30dc960bab648d6876547c515a80857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16992efb50344254aeb8bd83075d75fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7cbb0bb36c648a2b732ee81f25f3070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9549b550b85d404b996d651524da93da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"387e4001627c41fead717e26c0db101b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02d0daa75852468cb273f23982f70b36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c165b46028504b0ba3c2a83d8cddc485":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52ae2b6aac7e4361960a3d264ad063eb","IPY_MODEL_cca513bb787848a1b96f5c4d762187c0","IPY_MODEL_2bcde5693d60491f9aaf10d05cea00f5"],"layout":"IPY_MODEL_2911d679eab748a4804d78f548b0cceb"}},"52ae2b6aac7e4361960a3d264ad063eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_906a7c854598493e90e592f536de3c78","placeholder":"​","style":"IPY_MODEL_93b0d5933de440b29fc6b943095f4435","value":"Generating train split: "}},"cca513bb787848a1b96f5c4d762187c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da3809038e364d51842d877ca5eaa8ce","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7e00d1aa4894feab9ebf617534e616f","value":1}},"2bcde5693d60491f9aaf10d05cea00f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31d39955a18149e3b8d94847f43a0a0b","placeholder":"​","style":"IPY_MODEL_48cb13cdeec24cf3880019a620c79dcb","value":" 2187/0 [00:36&lt;00:00, 61.59 examples/s]"}},"2911d679eab748a4804d78f548b0cceb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"906a7c854598493e90e592f536de3c78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93b0d5933de440b29fc6b943095f4435":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da3809038e364d51842d877ca5eaa8ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a7e00d1aa4894feab9ebf617534e616f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31d39955a18149e3b8d94847f43a0a0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48cb13cdeec24cf3880019a620c79dcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":11832698,"sourceType":"datasetVersion","datasetId":7433728},{"sourceId":11843554,"sourceType":"datasetVersion","datasetId":7441272},{"sourceId":11843626,"sourceType":"datasetVersion","datasetId":7441321},{"sourceId":11843683,"sourceType":"datasetVersion","datasetId":7441354},{"sourceId":11881735,"sourceType":"datasetVersion","datasetId":7467488}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"fsspec>=2023.1.0,<2025.3.1\"\n!pip install datasets\n!pip install transformers\n!pip install librosa\n!pip install jiwer\n!pip install evaluate","metadata":{"id":"aSaVr64wxqD2","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:11:46.915721Z","iopub.execute_input":"2025-05-23T12:11:46.915927Z","iopub.status.idle":"2025-05-23T12:12:10.062988Z","shell.execute_reply.started":"2025-05-23T12:11:46.915902Z","shell.execute_reply":"2025-05-23T12:12:10.062270Z"}},"outputs":[{"name":"stdout","text":"Collecting fsspec<2025.3.1,>=2023.1.0\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.3->librosa) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.3->librosa) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.3->librosa) (2024.2.0)\nCollecting jiwer\n  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\nDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\nSuccessfully installed jiwer-3.1.0 rapidfuzz-3.13.0\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:12:21.048683Z","iopub.execute_input":"2025-05-23T12:12:21.049007Z","iopub.status.idle":"2025-05-23T12:12:21.451341Z","shell.execute_reply.started":"2025-05-23T12:12:21.048978Z","shell.execute_reply":"2025-05-23T12:12:21.450588Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"385a7bfa67964b07b51160e63c268945"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset, DatasetDict\nfrom transformers import (\n    Wav2Vec2Processor,\n    Wav2Vec2FeatureExtractor,\n    Wav2Vec2ForCTC,\n    Wav2Vec2CTCTokenizer,\n    TrainingArguments,\n    Trainer,\n    Wav2Vec2Config,\n    get_scheduler\n)\nfrom evaluate import load\nfrom dataclasses import dataclass, field\n\nimport os, json\nimport numpy as np\nfrom typing import Any, Dict, List, Optional, Union","metadata":{"id":"vONpsi_EskdZ","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:13:04.056378Z","iopub.execute_input":"2025-05-23T12:13:04.057156Z","iopub.status.idle":"2025-05-23T12:13:30.672666Z","shell.execute_reply.started":"2025-05-23T12:13:04.057132Z","shell.execute_reply":"2025-05-23T12:13:30.672108Z"}},"outputs":[{"name":"stderr","text":"2025-05-23 12:13:17.755365: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748002397.936043      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748002397.986489      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Configuration\nDATA_DIR = \"/kaggle/input/wav2vec2-0pfinetune/Dataset\"\nCHECKPOINT_DIR = \"/kaggle/working/checkpoints\"\nCHECKPOINT_PREFIX = f\"{CHECKPOINT_DIR}/w2v\"\nLOAD_CONFIG_PATH = \"load.config\"\nPROCESSOR_PATH = \"/kaggle/working/processor\"  # Path to save/load processor\nTOKENIZER_PATH = \"/kaggle/working/tokenizer\"  # Path to save/load tokenizer\n\nMODEL_NAME = \"/kaggle/input/wav2vec-demo-model2\"  # Base architecture | Please change it bro!\n\nBENGALI_TOKENIZER = \"/kaggle/input/tanmoyiowav2vec2-large-xlsr-bengali\"  # Bengali tokenizer\nBATCH_SIZE = 16\nGRADIENT_ACCUMULATION_STEPS = 2\nNUM_EPOCHS_PER_CHUNK = 3\n\n# Create necessary directories\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nos.makedirs(PROCESSOR_PATH, exist_ok=True)\nos.makedirs(TOKENIZER_PATH, exist_ok=True)","metadata":{"id":"L8YZU_VA8cMY","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:29:46.773890Z","iopub.execute_input":"2025-05-23T12:29:46.774396Z","iopub.status.idle":"2025-05-23T12:29:46.780895Z","shell.execute_reply.started":"2025-05-23T12:29:46.774375Z","shell.execute_reply":"2025-05-23T12:29:46.780282Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Configuration\nDATA_DIR = \"/kaggle/input/wav2vec2-0pfinetune/Dataset\"\nCHECKPOINT_DIR = \"/kaggle/input/checkpoints\"\nCHECKPOINT_PREFIX = f\"{CHECKPOINT_DIR}/w2v\"\nLOAD_CONFIG_PATH = \"/kaggle/input/checkpoints/load.config\"\nPROCESSOR_PATH = \"/kaggle/working/processor\"  # Path to save/load processor\nTOKENIZER_PATH = \"/kaggle/working/tokenizer\"  # Path to save/load tokenizer\n\nMODEL_NAME = \"/kaggle/input/wav2vec-demo-model2\"  # Base architecture | Please change it bro!\n\nBENGALI_TOKENIZER = \"/kaggle/input/tanmoyiowav2vec2-large-xlsr-bengali\"  # Bengali tokenizer\nBATCH_SIZE = 16\nGRADIENT_ACCUMULATION_STEPS = 2\nNUM_EPOCHS_PER_CHUNK = 3\n\n# Create necessary directories\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nos.makedirs(PROCESSOR_PATH, exist_ok=True)\nos.makedirs(TOKENIZER_PATH, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:13:53.422192Z","iopub.execute_input":"2025-05-23T12:13:53.422830Z","iopub.status.idle":"2025-05-23T12:13:53.430584Z","shell.execute_reply.started":"2025-05-23T12:13:53.422807Z","shell.execute_reply":"2025-05-23T12:13:53.429869Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# processed_dataset_chunk = load_dataset(\"parquet\", data_files=\"/content/drive/MyDrive/dataset_chunk_0.parquet\")","metadata":{"id":"7lOAxWTaxtJa","outputId":"f1b0a3cf-a0a5-4288-a9a3-3e22a5598b53"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"1. Determine iteration and Load data chunk","metadata":{"id":"F5E-fQ2p8u53"}},{"cell_type":"code","source":"if os.path.exists(LOAD_CONFIG_PATH):\n    with open(LOAD_CONFIG_PATH, \"r\") as f:\n        iter_index = int(f.read().strip())\nelse:\n    iter_index = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:27:04.190082Z","iopub.execute_input":"2025-05-23T15:27:04.190382Z","iopub.status.idle":"2025-05-23T15:27:04.194955Z","shell.execute_reply.started":"2025-05-23T15:27:04.190360Z","shell.execute_reply":"2025-05-23T15:27:04.194185Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"\niter_index = 0\nprint(f\"❇️ [LOAD INFO] Iteration Index: {iter_index}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:27:08.080666Z","iopub.execute_input":"2025-05-23T15:27:08.081143Z","iopub.status.idle":"2025-05-23T15:27:08.084872Z","shell.execute_reply.started":"2025-05-23T15:27:08.081121Z","shell.execute_reply":"2025-05-23T15:27:08.083992Z"}},"outputs":[{"name":"stdout","text":"❇️ [LOAD INFO] Iteration Index: 0\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"2. Load data from chunks","metadata":{"id":"t3K50TN09N1s"}},{"cell_type":"code","source":"# dataset = load_dataset(\"openslr\", \"SLR53\", split=\"train[:4%]\") # || Don't need the original dataset now. Therefore not loading it.\n\nchunk_path = f\"{DATA_DIR}/dataset_chunk_{iter_index}.parquet\"\nassert os.path.exists(chunk_path), f\"Missing dataset chunk: {chunk_path}\"\ndataset = load_dataset(\"parquet\", data_files={'train': chunk_path})\nprint(f\"❇️ [LOAD INFO] Loaded data from {chunk_path}\")\n\n# Split into train and validation\ntrain_valid_split = dataset['train'].train_test_split(\n    test_size=187,  # Specify exact number for validation\n    shuffle=True,   # Shuffle before splitting to randomize\n    seed=42         # For reproducibility\n)\n\n# Rename splits to match your intention\ndataset = DatasetDict({\n    'train': train_valid_split['train'],\n    'validation': train_valid_split['test']\n})\n\ntrain_dataset = dataset['train']\neval_dataset = dataset['validation']","metadata":{"id":"qIlIBrej9Qct","outputId":"a763e1b3-77d9-49bf-bc5d-5bda521f138a","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:27:10.900977Z","iopub.execute_input":"2025-05-23T15:27:10.901634Z","iopub.status.idle":"2025-05-23T15:27:25.149951Z","shell.execute_reply.started":"2025-05-23T15:27:10.901613Z","shell.execute_reply":"2025-05-23T15:27:25.149123Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24880d2c9baf4fb2aa35c3ec9bc800ef"}},"metadata":{}},{"name":"stdout","text":"❇️ [LOAD INFO] Loaded data from /kaggle/input/wav2vec2-0pfinetune/Dataset/dataset_chunk_0.parquet\n","output_type":"stream"}],"execution_count":94},{"cell_type":"code","source":"# data_len = processed_dataset_chunk['train'].num_rows\n\n# prepared_dataset = DatasetDict()\n# prepared_dataset['train'] = processed_dataset_chunk['train'].select((range(int(data_len * 0.8))))\n# prepared_dataset['test'] = processed_dataset_chunk['train'].select((range(int(data_len * 0.8), data_len)))\n\n# prepared_dataset","metadata":{"id":"RhnHJimaqh_0","outputId":"cc4b0936-9548-46bd-95dd-f7a93fc808ba"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from datasets import load_dataset\n\n# timit = load_dataset(\"parquet\", data_files=\"dataset_raw_500.parquet\")\n\n# timit_len = timit['train'].num_rows\n\n# timit['test'] = timit['train'].select((range(int(timit_len * 0.3))))\n# timit['train'] = timit['train'].select((range(int(timit_len * 0.3), timit_len)))\n\n# print(timit)","metadata":{"id":"m7Rw3xiX2tUz"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**3. Initialize or Load Processor, Model, and Training State**","metadata":{"id":"3a0nW_Kf96ey"}},{"cell_type":"code","source":"if iter_index == 0 or not os.path.exists(f\"{PROCESSOR_PATH}/preprocessor_config.json\"):\n    print(\"❇️ [LOAD INFO] Initializing new tokenizer and processor...\")\n\n    # Initialize the Bengali tokenizer\n    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\n        BENGALI_TOKENIZER,\n        unk_token=\"[UNK]\",\n        pad_token=\"[PAD]\",\n        word_delimiter_token=\"|\"\n    )\n\n    # Save tokenizer for future use\n    tokenizer.save_pretrained(TOKENIZER_PATH)\n\n    # Initialize processor with the Bengali tokenizer\n    processor = Wav2Vec2Processor.from_pretrained(\n        BENGALI_TOKENIZER,\n        tokenizer=tokenizer,\n        feature_extractor_kwargs={'sampling_rate': 16000}\n    )\n\n    # Save processor for future use\n    processor.save_pretrained(PROCESSOR_PATH)\nelse:\n    print(\"❇️ [LOAD INFO] Loading existing tokenizer and processor...\")\n    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(TOKENIZER_PATH)\n    processor = Wav2Vec2Processor.from_pretrained(PROCESSOR_PATH)\n\n\n\n# Setup model\nif iter_index == 0:\n    print(\"❇️ [LOAD INFO] Starting model training from scratch...\")\n\n    # Initialize model with appropriate config\n    config = Wav2Vec2Config.from_pretrained(\n        MODEL_NAME,\n        vocab_size=len(processor.tokenizer),\n        ctc_loss_reduction=\"mean\",\n        pad_token_id=processor.tokenizer.pad_token_id,\n    )\n\n    model = Wav2Vec2ForCTC.from_pretrained(\n        MODEL_NAME,\n        config=config,\n        ignore_mismatched_sizes=True\n    )\n\n    # The faeture_extractor CNN was trained enough and should be freezed (according to the paper)\n    model.freeze_feature_extractor()\n\n    model.to(\"cuda\")\n\n    # Initialize optimizer and scheduler\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    scheduler = get_scheduler(\n        \"linear\",\n        optimizer=optimizer,\n        num_warmup_steps=100,\n        num_training_steps=(NUM_EPOCHS_PER_CHUNK * (iter_index + 1)) * (len(train_dataset) // BATCH_SIZE)\n    )\n\nelse:\n    print(f\"❇️ [LOAD INFO] Resuming from checkpoint {iter_index-1}...\")\n\n    # Load model from checkpoint\n    model = Wav2Vec2ForCTC.from_pretrained(f\"{CHECKPOINT_PREFIX}\")\n\n    model.to(\"cuda\")\n\n\n    # Load optimizer state\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n    optimizer.load_state_dict(torch.load(f\"{CHECKPOINT_PREFIX}/optimizer.pt\"))\n\n    # Load scheduler state\n    scheduler = get_scheduler(\n        \"linear\",\n        optimizer=optimizer,\n        num_warmup_steps=100,\n        num_training_steps=(NUM_EPOCHS_PER_CHUNK * (iter_index + 1)) * (len(train_dataset) // BATCH_SIZE)\n    )\n    scheduler.load_state_dict(torch.load(f\"{CHECKPOINT_PREFIX}/scheduler.pt\"))\n","metadata":{"id":"RxD37Ynp96RN","outputId":"debfeab6-4aac-482a-e609-e004f4db2f46","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:27:30.867072Z","iopub.execute_input":"2025-05-23T15:27:30.867653Z","iopub.status.idle":"2025-05-23T15:27:35.025919Z","shell.execute_reply.started":"2025-05-23T15:27:30.867631Z","shell.execute_reply":"2025-05-23T15:27:35.025262Z"}},"outputs":[{"name":"stdout","text":"❇️ [LOAD INFO] Initializing new tokenizer and processor...\n❇️ [LOAD INFO] Starting model training from scratch...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at /kaggle/input/wav2vec-demo-model2 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:2175: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5. Please use the equivalent `freeze_feature_encoder` method instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"**3.2 Loading tokenizer and processor** <br>\nThis step is only required for data_collator and won't use for data processing at this step as data is already processed accordingly","metadata":{"id":"IKbW6C9Njz9o"}},{"cell_type":"code","source":"tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\n    \"tanmoyio/wav2vec2-large-xlsr-bengali\",\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    word_delimiter_token=\"|\"\n)\n\nvocab_dict = tokenizer.vocab\n\nwith open('vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)\n\nfeature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\nprocessor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)","metadata":{"id":"m6y1jaCBloQG","outputId":"433a0b72-931a-4102-8f09-0b5b491d3468","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:58:37.907163Z","iopub.execute_input":"2025-05-23T12:58:37.907501Z","iopub.status.idle":"2025-05-23T12:58:37.988727Z","shell.execute_reply.started":"2025-05-23T12:58:37.907478Z","shell.execute_reply":"2025-05-23T12:58:37.987986Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:311: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"@dataclass\nclass DataCollatorCTCWithPadding:\n    \"\"\"\n    Data collator that will dynamically pad the inputs received.\n    Args:\n        processor (:class:`~transformers.Wav2Vec2Processor`)\n            The processor used for proccessing the data.\n        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n            among:\n            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n              sequence if provided).\n            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n              maximum acceptable input length for the model if that argument is not provided.\n            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n              different lengths).\n        max_length (:obj:`int`, `optional`):\n            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n        max_length_labels (:obj:`int`, `optional`):\n            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n        pad_to_multiple_of (:obj:`int`, `optional`):\n            If set will pad the sequence to a multiple of the provided value.\n            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n            7.5 (Volta).\n    \"\"\"\n\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n    max_length: Optional[int] = None\n    max_length_labels: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    pad_to_multiple_of_labels: Optional[int] = None\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                max_length=self.max_length_labels,\n                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n                return_tensors=\"pt\",\n            )\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"id":"Zfpsj1j-mTJe","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:14:44.755767Z","iopub.execute_input":"2025-05-23T12:14:44.756466Z","iopub.status.idle":"2025-05-23T12:14:44.763948Z","shell.execute_reply.started":"2025-05-23T12:14:44.756441Z","shell.execute_reply":"2025-05-23T12:14:44.763264Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"id":"-eHIWjDZmvHR","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:14:50.610599Z","iopub.execute_input":"2025-05-23T12:14:50.611135Z","iopub.status.idle":"2025-05-23T12:14:50.614521Z","shell.execute_reply.started":"2025-05-23T12:14:50.611115Z","shell.execute_reply":"2025-05-23T12:14:50.613795Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"wer_metric = load(\"wer\")\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"id":"mdTFXXmBm0tv","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:15:00.876448Z","iopub.execute_input":"2025-05-23T12:15:00.877040Z","iopub.status.idle":"2025-05-23T12:15:01.302412Z","shell.execute_reply.started":"2025-05-23T12:15:00.877021Z","shell.execute_reply":"2025-05-23T12:15:01.301907Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"001115cea5b1436caec2e722bd76bded"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# # Loading a pre-trained checkpoint\n# model = Wav2Vec2ForCTC.from_pretrained(\n#     \"imrnh/wav2vec_demo_model\",\n#     ctc_loss_reduction=\"mean\",\n#     pad_token_id=processor.tokenizer.pad_token_id,\n# )\n\n","metadata":{"id":"Y41FAlerpO95","outputId":"d700cad1-28f0-478c-d488-86dbb7e73d49"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"repo_name = \"wav2vec_finetune_bengali_asr\"\n\ntraining_args = TrainingArguments(\n  output_dir=repo_name,\n  group_by_length=True,\n  per_device_train_batch_size=24,\n  eval_strategy=\"steps\",\n  num_train_epochs=1,\n  fp16=True,\n  gradient_checkpointing=True,\n  save_steps=50,\n  eval_steps=50,\n  logging_steps=50,\n  learning_rate=1e-4,\n  weight_decay=0.005,\n  warmup_steps=50,\n  save_total_limit=2,\n  report_to=\"none\",\n)","metadata":{"id":"w-PUDIYIpde_","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:22:25.686692Z","iopub.execute_input":"2025-05-23T15:22:25.687413Z","iopub.status.idle":"2025-05-23T15:22:25.722107Z","shell.execute_reply.started":"2025-05-23T15:22:25.687388Z","shell.execute_reply":"2025-05-23T15:22:25.721269Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=processor.feature_extractor,\n    optimizers = (optimizer, scheduler)\n)","metadata":{"id":"C9TJMzzUpjJm","outputId":"3be0b6a6-62d7-47b0-f222-702367a89b52","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:33:02.021367Z","iopub.execute_input":"2025-05-23T15:33:02.022047Z","iopub.status.idle":"2025-05-23T15:33:02.037399Z","shell.execute_reply.started":"2025-05-23T15:33:02.022006Z","shell.execute_reply":"2025-05-23T15:33:02.036643Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1112584941.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"if iter_index > 0 and os.path.exists(f\"{CHECKPOINT_PREFIX}/trainer_state.json\"): # Resume training state if available\n    print(\"❇️ [RESUME TRAINING]\")\n    trainer.train(resume_from_checkpoint=f\"{CHECKPOINT_PREFIX}\")\nelse:\n    print(\"❇️ [STARTING TRAINING FROM SCRATCH]\")\n    trainer.train()","metadata":{"id":"QLjFfCXrrgge","outputId":"e6730acc-4f08-40af-8ea0-98b80ee8fdb8","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:33:05.146888Z","iopub.execute_input":"2025-05-23T15:33:05.147540Z","execution_failed":"2025-05-23T15:33:22.396Z"}},"outputs":[{"name":"stdout","text":"❇️ [STARTING TRAINING FROM SCRATCH]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"trainer.save_model(f\"{CHECKPOINT_PREFIX}\") # Save pre-trained model\n\nprocessor.save_pretrained(f\"{CHECKPOINT_PREFIX}\") # Save pre-trained tokenizer\n\ntorch.save(optimizer.state_dict(), f\"{CHECKPOINT_PREFIX}/optimizer.pt\") # Save optimizer\n\ntorch.save(scheduler.state_dict(), f\"{CHECKPOINT_PREFIX}/scheduler.pt\") # Save scheduler\n\ntrainer.state.save_to_json(f\"{CHECKPOINT_PREFIX}/trainer_state.json\") # Save training state\n\n# Update iteration index\nwith open(LOAD_CONFIG_PATH, \"w\") as f:\n    f.write(str(iter_index + 1))\n\nprint(f\"❇️ [LOAD INFO] Finished training on chunk {iter_index}. Ready for next chunk.\")\nprint(f\"\\nSaved checkpoint to {CHECKPOINT_PREFIX}_{iter_index}\")","metadata":{"id":"AAxWAS9I5U5V","outputId":"2dfb33fe-d19c-4d65-e34c-67a58c2ecfa3","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:21:28.128533Z","iopub.execute_input":"2025-05-23T15:21:28.128798Z","iopub.status.idle":"2025-05-23T15:21:30.678904Z","shell.execute_reply.started":"2025-05-23T15:21:28.128779Z","shell.execute_reply":"2025-05-23T15:21:30.678066Z"}},"outputs":[{"name":"stdout","text":"❇️ [LOAD INFO] Finished training on chunk 16. Ready for next chunk.\n\nSaved checkpoint to /kaggle/working/checkpoints/w2v_16\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"from huggingface_hub import HfApi\nimport torch\n\nREPO_NAME = \"Anisa206/wav2vec_finetune_bengali_asr\"\napi = HfApi()\n\n# ✅ Save training artifacts locally\ntorch.save(optimizer.state_dict(), \"optimizer.pt\")\ntorch.save(scheduler.state_dict(), \"scheduler.pt\")\ntrainer.state.save_to_json(\"trainer_state.json\")\nwith open(\"load.config\", \"w\") as f:\n    f.write(str(iter_index + 1))\n\n# ✅ Upload all to Hugging Face under the /w2v directory\nfor filename in [\"optimizer.pt\", \"scheduler.pt\", \"trainer_state.json\", \"load.config\"]:\n    api.upload_file(\n        path_or_fileobj=filename,\n        path_in_repo=f\"w2v/{filename}\",\n        repo_id=REPO_NAME\n    )\n\nprint(\"✅ Uploaded all training state files to w2v/ on Hugging Face Hub.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:21:34.169297Z","iopub.execute_input":"2025-05-23T15:21:34.169586Z","iopub.status.idle":"2025-05-23T15:21:53.619184Z","shell.execute_reply.started":"2025-05-23T15:21:34.169566Z","shell.execute_reply":"2025-05-23T15:21:53.618487Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading...:   0%|          | 0.00/756M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24d04c8c04b54cffb1a2ca3b646f2d52"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Uploading...:   0%|          | 0.00/1.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03fdd349f34b49d2b7140c267add0917"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"✅ Uploaded all training state files to w2v/ on Hugging Face Hub.\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"import shutil\nimport os\nfrom IPython.display import FileLink\n\n# Copy all checkpoints + config to a slim directory\nshutil.copytree('/kaggle/working/checkpoints', '/kaggle/working/slim_checkpoints', dirs_exist_ok=True)\nshutil.copy('/kaggle/working/load.config', '/kaggle/working/slim_checkpoints/load.config')\n\n# Zip the slim checkpoints folder\n!zip -r /kaggle/working/slim_checkpoints.zip /kaggle/working/slim_checkpoints > /dev/null\n\n# Create download link\nFileLink('/kaggle/working/slim_checkpoints.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T14:44:16.623466Z","iopub.execute_input":"2025-05-21T14:44:16.623704Z","iopub.status.idle":"2025-05-21T14:45:17.783232Z","shell.execute_reply.started":"2025-05-21T14:44:16.623687Z","shell.execute_reply":"2025-05-21T14:45:17.782500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# Copy the safetensors file to the root of /kaggle/working\nshutil.copy('/kaggle/working/slim_checkpoints/w2v/model.safetensors', '/kaggle/working/model.safetensors')\n\n# Zip just the file\n!zip -j /kaggle/working/model_safetensors.zip /kaggle/working/model.safetensors > /dev/null\n\n# Create a download link\nFileLink('/kaggle/working/model_safetensors.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:04:00.089813Z","iopub.execute_input":"2025-05-21T15:04:00.090419Z","iopub.status.idle":"2025-05-21T15:04:20.889610Z","shell.execute_reply.started":"2025-05-21T15:04:00.090393Z","shell.execute_reply":"2025-05-21T15:04:20.888709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# Copy the safetensors file to the root of /kaggle/working\nshutil.copy('/kaggle/working/slim_checkpoints/w2v/optimizer.pt', '/kaggle/working/optimizer.pt')\n\n# Zip just the file\n!zip -j /kaggle/working/optimizer_pt.zip /kaggle/working/optimizer.pt > /dev/null\n\n# Create a download link\nFileLink('/kaggle/working/optimizer_pt.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:24:56.858799Z","iopub.execute_input":"2025-05-21T15:24:56.859117Z","iopub.status.idle":"2025-05-21T15:25:36.501766Z","shell.execute_reply.started":"2025-05-21T15:24:56.859092Z","shell.execute_reply":"2025-05-21T15:25:36.501022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\n# Create an \"outputs\" directory in /kaggle/working/ if it doesn't exist\noutput_dir = \"/kaggle/working/outputs\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Move the zip file there\nshutil.move(\"/kaggle/working/slim_checkpoints.zip\", f\"{output_dir}/slim_checkpoints.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:13:30.551679Z","iopub.execute_input":"2025-05-21T15:13:30.552299Z","iopub.status.idle":"2025-05-21T15:13:30.558935Z","shell.execute_reply.started":"2025-05-21T15:13:30.552277Z","shell.execute_reply":"2025-05-21T15:13:30.558049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\ndir_path = \"/kaggle/working/checkpoints/w2v_0\"\n\nif os.path.exists(dir_path) and os.path.isdir(dir_path):\n    shutil.rmtree(dir_path)\n    print(\"✅ Directory deleted.\")\nelse:\n    print(\"⚠️ Directory not found.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T05:55:26.961798Z","iopub.execute_input":"2025-05-20T05:55:26.962448Z","iopub.status.idle":"2025-05-20T05:55:27.187937Z","shell.execute_reply.started":"2025-05-20T05:55:26.962430Z","shell.execute_reply":"2025-05-20T05:55:27.187307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 00203b850e.flac\n\n# /root/.cache/huggingface/datasets/downloads/extracted/26bb8427288fee2953f209d1a76d10a296b928d87eeee035cf51e56f8508f2fe/asr_bengali/data/00/00203b850e.flac","metadata":{"id":"3IF_3YG-EQN5"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"bhCwg5dTEXbb"},"outputs":[],"execution_count":null}]}